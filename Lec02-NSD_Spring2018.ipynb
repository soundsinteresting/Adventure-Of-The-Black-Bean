{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic calculus and its applications in quantitative finance\n",
    "## National School of Development, Spring 2018 \n",
    "\n",
    "## Lecture 2: Basic martingale theory\n",
    "\n",
    "\n",
    "Tai-Ho Wang (王 太 和)   \n",
    "   \n",
    "<h2><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2014/07/BaruchLogo2.png\" align = \"center\" height=50 width=190></h2>\n",
    "and \n",
    "<br>\n",
    "<h2><img src=\"NSD-logo.jpeg\", height=120, width=480></h2>\n",
    "\n",
    "$$\n",
    "\\newcommand{\\bea}{\\begin{eqnarray}}\n",
    "\\newcommand{\\eea}{\\end{eqnarray}}\n",
    "\\newcommand{\\supp}{\\mathrm{supp}}\n",
    "\\newcommand{\\F}{\\mathcal{F} }\n",
    "\\newcommand{\\G}{\\mathcal{G} }\n",
    "\\newcommand{\\cF}{\\mathcal{F} }\n",
    "\\newcommand{\\E}{\\mathbb{E} }\n",
    "\\newcommand{\\Eof}[1]{\\mathbb{E}\\left[ #1 \\right]}\n",
    "\\def\\Cov{{ \\mbox{Cov} }}\n",
    "\\def\\Var{{ \\mbox{Var} }}\n",
    "\\newcommand{\\1}{\\mathbf{1} }\n",
    "\\newcommand{\\P}{\\mathbb{P} }\n",
    "\\newcommand{\\Pof}[1]{\\mathbb{P}\\left[ #1 \\right]}\n",
    "\\newcommand{\\QQ}{\\mathbb{Q} }\n",
    "\\newcommand{\\R}{\\mathbb{R} }\n",
    "\\newcommand{\\DD}{\\mathbb{D} }\n",
    "\\newcommand{\\HH}{\\mathbb{H} }\n",
    "\\newcommand{\\spn}{\\mathrm{span} }\n",
    "\\newcommand{\\cov}{\\mathrm{cov} }\n",
    "\\newcommand{\\HS}{\\mathcal{L}_{\\mathrm{HS}} }\n",
    "\\newcommand{\\trace}{\\mathrm{trace} }\n",
    "\\newcommand{\\LL}{\\mathcal{L} }\n",
    "\\newcommand{\\s}{\\mathcal{S} }\n",
    "\\newcommand{\\ee}{\\mathcal{E} }\n",
    "\\newcommand{\\ff}{\\mathcal{F} }\n",
    "\\newcommand{\\hh}{\\mathcal{H} }\n",
    "\\newcommand{\\bb}{\\mathcal{B} }\n",
    "\\newcommand{\\dd}{\\mathcal{D} }\n",
    "\\newcommand{\\g}{\\mathcal{G} }\n",
    "\\newcommand{\\half}{\\frac{1}{2} }\n",
    "\\newcommand{\\T}{\\mathcal{T} }\n",
    "\\newcommand{\\bit}{\\begin{itemize}}\n",
    "\\newcommand{\\eit}{\\end{itemize}}\n",
    "\\newcommand{\\beq}{\\begin{equation}}\n",
    "\\newcommand{\\eeq}{\\end{equation}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline of Lecture 2\n",
    "\n",
    "* Review: filtered probability space, adapted stochastic processes\n",
    "\n",
    "* Martingale, submartingale, and supermartingale\n",
    "\n",
    "* Martingale transformation and discrete stochastic integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability space\n",
    "\n",
    "A probability space, usually denoted by a triplet $(\\Omega,\\cF,\\P)$, consists of \n",
    "\n",
    "* a sample space $\\Omega$, which contains all possible outcomes of random experiments/scenarios under consideration\n",
    "\n",
    "\n",
    "* a $\\sigma$-algebra containing all the subsets to which probabilities are to be assigned.\n",
    "\n",
    "\n",
    "* a probability measure, which is a set function assigning probabilities to every event in $\\cF$ and satisfies \n",
    "    \n",
    "    * $\\Pof{\\Omega}=1$\n",
    "    \n",
    "    * $0 \\leq \\Pof{E} \\leq 1$ for every $E \\in \\cF$ \n",
    "    <br>   \n",
    "    * (countable additivity) If $E_1,E_2,\\cdots \\in \\cF$ and $E_i\\cap E_j = \\emptyset$ for all $i \\neq j$, then \n",
    "    \n",
    "    $$\n",
    "      \\Pof{\\bigcup_{i=1}^\\infty E_i} = \\sum_{i=1}^\\infty \\Pof{E_i}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stochastic process\n",
    "\n",
    "Let $(\\Omega, \\cF, \\P)$ be a probability space and $T=\\mathbb{N}\\cup\\{0\\}$ (the set of all nonnegative integers), $T = \\R$, or $T = \\{0,1,2,\\cdots, N\\}$, $N < \\infty$.\n",
    "\n",
    "#### Definition\n",
    "A stochastic process is a map $X:T \\times \\Omega \\to \\R$ such that, for each $t\\in T$, $X_t=X_t(\\omega):=X(t,\\omega)$ is a random variable.\n",
    "\n",
    "\n",
    "* For each fixed $\\omega \\in \\Omega$, the mapping $X(\\cdot,\\omega):T \\to \\R$ is called a *sample path*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Filtration and filtered probability space\n",
    "\n",
    "\n",
    "#### Definition (Filtration)\n",
    "\n",
    "An increasing family of $\\sigma$-fields indexed by the set $T$, i.e., $\\{ \\cF_t \\}_{t\\in T}$ is a family of $\\sigma$-fields such that $\\cF_s \\subset \\cF_t$ for every $s,t \\in T$ and $s < t$, is called a *filtration*. We\n",
    "  usually assume $\\cF_0 = \\{ \\emptyset, \\Omega\\}$ and $\\cF_N = \\cF$.\n",
    "\n",
    "\n",
    "#### Definition (Filtered probability space)\n",
    "\n",
    "The probability space $(\\Omega, \\cF, \\P)$ equipped with a filtration $\\cF_t$, denoted by $(\\Omega, \\cF_t, \\P)$, is called a *filtered probability space*.\n",
    "\n",
    "\n",
    "#### Definition (Adaptedness)\n",
    "\n",
    "A stochastic process $X$ is called *adapted* to the filtration $\\cF_t$ if $X_t$ is $\\cF_t$-measurable for every $t \\in T$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Martingale, sub, and super martingales\n",
    "\n",
    "Let $(\\Omega,\\cF_t,\\P)$ be a filtered probability space. A stochastic process $X$ is called a *martingale*\n",
    "(*submartingale*, *supermartingale*) with respect to the filtration\n",
    "$\\cF_t$ if it satisfies\n",
    "\n",
    "\n",
    "* $\\E|X_t| < \\infty$ for every $t \\in T$.\n",
    "\n",
    "\n",
    "* $X$ is adapted to $\\cF_t$.\n",
    "\n",
    "\n",
    "* $\\E[ X_{t+1} | \\cF_t] = (\\geq,\\leq) X_t$ for all $t \\in T$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examples of martingale\n",
    "\n",
    "* A natural way to construct a martingale is by starting with an integrable random variable at the terminal time then conditioning backwards accordingly with respect to the filtration. Specifically, Let $Y$ be a random variable with $\\E|Y| < \\infty$ and define $X_t = \\E[Y | \\cF_t]$. Then $X_t$ apparently is a martingale.\n",
    "\n",
    "\n",
    "* A natural question to ask is: do all the martingales come from conditioning backwards a terminal random variable? The answer is obviously yes if the time domain $T$ is a finite set. However, if the time domain is infinite, then we are essentially asking if the martingale sequence converges. \n",
    "\n",
    "\n",
    "* Let $\\xi_1, \\xi_2, \\cdots$ be an iid sequence of random variables with $\\P[\\xi_i=1] = p$ and $\\P[\\xi_i=-1] = 1 - p$, for $i=1,2,\\cdots$, where $0 \\leq p \\leq 1$. Define $X_t = \\sum_{i=1}^t \\xi_i$. Then $X_t$ is a martingale if $p=1/2$; a supermartingale if $p<1/2$; a submartingale if $p>1/2$.\n",
    "\n",
    "\n",
    "* Let $\\xi_1, \\xi_2, \\cdots$ be a sequence of integrable independent random variables with $\\E[\\xi_i] = 0$, for $i=1,2,\\cdots$. Define $X_t = \\sum_{i=1}^t \\xi_i$, i.e., $X_t$ is a random walk. Then $X_t$ is a martingale.\n",
    "\n",
    "\n",
    "* If $X_t$ and $Y_t$ are two supermartingales, then $Z_t = X_t \\wedge Y_t$ is also a supermartingale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Properties of martingale\n",
    "\n",
    "* For $t > s$,\n",
    "\n",
    "    * if $X_t$ is a supermartingale, then $\\E[X_t | \\cF_s] \\leq X_s$.\n",
    "    \n",
    "    * if $X_t$ is a submartingale, then $\\E[X_t | \\cF_s] \\geq X_s$.\n",
    "        \n",
    "    * if $X_t$ is a martingale, then $\\E[X_t | \\cF_s] = X_s$.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predictable process\n",
    "\n",
    "Let $(\\Omega, \\cF_t, \\P)$ be a filtered probability space.\n",
    "\n",
    "#### Definition (Predictable processes)\n",
    "\n",
    "A stochastic process $H$ defined on $\\Omega$ is called *predictable* if $H_t$ is $\\cF_{t-1}$-measurable for every $t \\in T$. Note that, as a convention, we don't define $H_0$. \n",
    "\n",
    "\n",
    "#### Theorem (Doob's decomposition)\n",
    "\n",
    "Any submartingale $X_t$ can be written in a unique way as $X_t = M_t + A_t$, where $M_t$ is a martingale and $A_t$ is a predictable and increasing sequence with $A_0=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discrete stochastic integral\n",
    "\n",
    "The *stochastic integral* of the predictable process $H_t$ with respect to the supermartingale (martingale, submartingale) $X_t$, denoted by $(H\\cdot X)_t$, is defined as\n",
    "\n",
    "$$\n",
    "  (H\\cdot X)_t = \\sum_{s=1}^t H_s \\Delta X_s,\n",
    "$$\n",
    "\n",
    "where $\\Delta X_s = X_s - X_{s-1}$. As a convention, we define $(H \\cdot X)_0 = 0$.\n",
    "\n",
    "#### Remark\n",
    "\n",
    "Stochastic integral is a clever way of tracking P&L of a trading strategy over an investment horizon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Properties of stochastic integral\n",
    "\n",
    "\n",
    "* Let $X_t$ be a supermartingale (submartingale) and $H_t$ be nonnegative, bounded and predictable. Then $(H\\cdot X)_t$ is a supermartingale (submartingale).\n",
    "\n",
    "\n",
    "* Let $X_t$ be a submartingale. Suppose $H_t$ and $K_t$ are bounded and predictable such that $H_t \\geq K_t$ for every $t$. Then $\\E[(H\\cdot X)_t] \\geq \\E[(K \\cdot X)_t]$ for every $t \\in T$.\n",
    "\n",
    "\n",
    "* Let $X_t$ be a martingale and $H_t$ be bounded and predictable. (need not be nonnegative!) Then $(H\\cdot X)_t$ is a martingale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stopping time\n",
    "\n",
    "A random variable $\\tau:\\Omega \\to T$ is called a stopping time if $\\{\\tau \\leq t\\} \\in \\F_t$ for all $t \\in T$.\n",
    "\n",
    "\n",
    "* In the discrete time case, the above definition of stopping time is equivalent to $\\{ \\tau = t \\} \\in \\F_t$ for all $t \\in T$.\n",
    "\n",
    "\n",
    "* Typical stopping times are hitting times or the first time that a process leaves/enters a specific interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stopped processes\n",
    "\n",
    "#### Theorem \n",
    "\n",
    "If $\\tau$ is a stopping time and $X_t$ is a submartingale (martingale, supermartingale), then the stopped process $X_{\\tau \\wedge t}$ is also a submartingale (martingale, supermartingale).\n",
    "\n",
    "\n",
    "#### Theorem\n",
    "\n",
    "If $X_t$ is a submartingale and $\\tau$ is a stopping time with $\\P[\\tau \\leq k] = 1$ (i.e., $\\tau$ is almost surely bounded above by $k$) for some $k\\in T$, then we have\n",
    "\n",
    "$$\n",
    "  \\E[X_0] \\leq \\E[X_{\\tau}] \\leq \\E[X_k].\n",
    "$$\n",
    "\n",
    "Moreover, if $\\tau$ and $\\sigma$ are stopping times with\n",
    "$\\P[\\sigma \\leq \\tau \\leq k] = 1$ (i.e., $\\sigma$ is almost surely\n",
    "less than or equal to $\\tau$ and both of them are bounded above by\n",
    "$k$), then\n",
    "\n",
    "$$\n",
    "  \\E[X_{\\sigma}] \\leq \\E[X_{\\tau}].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The optional stopping theorem\n",
    "If $\\sigma \\leq \\tau$ are stopping times and $Y_{t\\wedge \\tau}$ is a uniformly integrable submartingale then \n",
    "\n",
    "$$\n",
    "\\E[Y_\\sigma] \\leq \\E[Y_\\tau]\n",
    "$$ \n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "Y_\\sigma \\leq \\E[Y_\\tau | \\F_\\sigma].\n",
    "$$\n",
    "\n",
    "In partular, if $Y_{t\\wedge \\tau}$ is a uniformly integrable martingale, then $Y_\\sigma = \\E[Y_\\tau | \\F_\\sigma]$. In other words, up to the technical condition (i.e., the uniform integrability), the martingality holds even for stopping times. \n",
    "\n",
    "\n",
    "#### Definition (Uniform integrability)\n",
    "A family of random variables $\\{X_\\alpha\\}_{\\alpha\\in A}$, where $A$ is an index set, is called *uniformly integrable* if it satisfies\n",
    "\n",
    "$$\n",
    "  \\lim_{M \\to \\infty} \\sup_{\\alpha \\in A}\\Eof{|X_\\alpha|;|X_\\alpha| \\geq M} = 0\n",
    "$$\n",
    "\n",
    "Typical examples are\n",
    "\n",
    "* Unformly bounded family of random variables, i.e., there exists an $M > 0$ such that $|X_\\alpha| \\leq M$, for all $\\alpha \\in A$.\n",
    "\n",
    "\n",
    "* $X_\\alpha$'s are dominated by an integrable random variable, i.e., there exists a random variable $Y \\in L^1$ such that $|X_\\alpha| \\leq Y$ almost surely for all $\\alpha \\in A$."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
